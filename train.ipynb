{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "image_files, labels = utils.getprocessedfilelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_road\\\\images.npy', image_files)\n",
    "np.save('data_road\\\\labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "image_files = np.load('data_road\\\\images.npy')\n",
    "labels = np.load('data_road\\\\labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'data_road\\\\processed_images\\\\umm_000000_0.jpg', array([160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160.]))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "data = tf.data.Dataset.from_tensor_slices((image_files, labels))\n",
    "a = data.as_numpy_iterator()\n",
    "b = a.next()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0.11764706, 0.15686275, 0.12156863],\n",
      "        [0.09019608, 0.11764706, 0.08627451],\n",
      "        [0.13333334, 0.12941177, 0.10980392],\n",
      "        ...,\n",
      "        [0.16078432, 0.23137255, 0.13725491],\n",
      "        [0.19607843, 0.25882354, 0.15686275],\n",
      "        [0.23137255, 0.28627452, 0.18431373]],\n",
      "\n",
      "       [[0.09803922, 0.14509805, 0.10588235],\n",
      "        [0.07843138, 0.11764706, 0.08235294],\n",
      "        [0.14901961, 0.16078432, 0.13333334],\n",
      "        ...,\n",
      "        [0.10980392, 0.16862746, 0.09411765],\n",
      "        [0.14117648, 0.2       , 0.11764706],\n",
      "        [0.18431373, 0.23921569, 0.14901961]],\n",
      "\n",
      "       [[0.09019608, 0.16078432, 0.11372549],\n",
      "        [0.07450981, 0.13725491, 0.09411765],\n",
      "        [0.14117648, 0.18039216, 0.14509805],\n",
      "        ...,\n",
      "        [0.03137255, 0.07843138, 0.03921569],\n",
      "        [0.04313726, 0.09019608, 0.05098039],\n",
      "        [0.0627451 , 0.11764706, 0.06666667]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.4862745 , 0.49803922, 0.47058824],\n",
      "        [0.4627451 , 0.45882353, 0.4392157 ],\n",
      "        [0.4745098 , 0.44313726, 0.43137255],\n",
      "        ...,\n",
      "        [0.47058824, 0.46666667, 0.44705883],\n",
      "        [0.4509804 , 0.44705883, 0.43137255],\n",
      "        [0.44705883, 0.44313726, 0.42745098]],\n",
      "\n",
      "       [[0.4509804 , 0.45882353, 0.41568628],\n",
      "        [0.43529412, 0.43529412, 0.40392157],\n",
      "        [0.49411765, 0.45882353, 0.4627451 ],\n",
      "        ...,\n",
      "        [0.5058824 , 0.50980395, 0.4862745 ],\n",
      "        [0.48235294, 0.4862745 , 0.46666667],\n",
      "        [0.4745098 , 0.47843137, 0.45882353]],\n",
      "\n",
      "       [[0.44705883, 0.45490196, 0.40392157],\n",
      "        [0.4       , 0.4       , 0.36862746],\n",
      "        [0.4509804 , 0.4117647 , 0.41568628],\n",
      "        ...,\n",
      "        [0.5254902 , 0.5294118 , 0.5058824 ],\n",
      "        [0.5058824 , 0.50980395, 0.49019608],\n",
      "        [0.49803922, 0.5019608 , 0.48235294]]], dtype=float32), array([ 36.,  36.,  35.,  35.,  35.,  34.,  34.,  33.,  33.,  33.,  32.,\n",
      "        32.,  32.,  31.,  31.,  31.,  30.,  30.,  30.,  29.,  29.,  29.,\n",
      "        28.,  28.,  28.,  28.,  28.,  28.,  28.,  28.,  28.,  27.,  27.,\n",
      "        27.,  27.,  27.,  27.,  27.,  27.,  27.,  27.,  26.,  26.,  26.,\n",
      "        26.,  26.,  26.,  26.,  26.,  26.,  26.,  25.,  25.,  25.,  25.,\n",
      "        25.,  25.,  25.,  25.,  25.,  25.,  24.,  24.,  24.,  25.,  28.,\n",
      "        31.,  34.,  37.,  39.,  42.,  45.,  48.,  51.,  52.,  52.,  52.,\n",
      "        52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,\n",
      "        52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,\n",
      "        52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,\n",
      "        52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,\n",
      "        52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  52.,  53.,  53.,\n",
      "        54.,  54.,  55.,  55.,  56.,  56.,  57.,  57.,  58.,  58.,  59.,\n",
      "        59.,  60.,  60.,  61.,  61.,  62.,  62.,  63.,  63.,  64.,  64.,\n",
      "        65.,  65.,  66.,  66.,  67.,  67.,  68.,  68.,  69.,  69.,  70.,\n",
      "        70.,  71.,  71.,  72.,  72.,  73.,  73.,  74.,  74.,  75.,  75.,\n",
      "        76.,  76.,  77.,  77.,  77.,  78.,  78.,  79.,  79.,  80.,  80.,\n",
      "        80.,  81.,  81.,  82.,  82.,  83.,  83.,  84.,  84.,  84.,  85.,\n",
      "        85.,  86.,  86.,  87.,  87.,  87.,  88.,  88.,  89.,  89.,  90.,\n",
      "        90.,  91.,  91.,  91.,  92.,  92.,  93.,  93.,  94.,  94.,  94.,\n",
      "        95.,  95.,  96.,  96.,  97.,  97.,  98.,  98.,  99.,  99., 100.,\n",
      "       101., 102., 102., 103., 104., 104., 105., 106., 106., 107., 108.,\n",
      "       109., 109., 110., 111., 111., 112., 113., 113., 114., 115., 116.,\n",
      "       116., 117., 118., 118., 119., 120., 121., 121., 122., 123., 123.,\n",
      "       124., 125., 125., 126., 127., 128., 128., 129., 130., 130., 131.,\n",
      "       132., 132., 133., 134., 135., 135., 136., 137., 138., 139., 140.,\n",
      "       141., 141., 142., 143., 144., 145., 146., 147., 148., 149., 150.,\n",
      "       150., 151., 152., 153., 154., 155., 156., 157., 158., 159., 159.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160., 160., 160., 160., 160., 160.,\n",
      "       160., 160., 160., 160., 160., 160.]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def readimage(image_file, label):\n",
    "    image = tf.io.decode_jpeg(tf.io.read_file(image_file)) / 255\n",
    "    return image, label\n",
    "\n",
    "shuffled_ds = data.shuffle(20000).map(readimage, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "iter_ = shuffled_ds.as_numpy_iterator()\n",
    "a = iter_.next()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv1D, LSTM, MaxPool2D, Flatten, InputLayer, Reshape, TimeDistributed\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(160,600,3)),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        MaxPool2D(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        MaxPool2D(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        MaxPool2D(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        TimeDistributed(LSTM(64, return_sequences=True)),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        TimeDistributed(LSTM(64, return_sequences=True)),\n",
    "        Conv2D(64, (5,1), strides=(4,1), activation='relu'),\n",
    "        Conv2D(1, (4,1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(600, activation='linear')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join('ckpt','weights.{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
    "        monitor='val_loss', mode='min', save_best_only=True)\n",
    "]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = shuffled_ds.take(20000).batch(batch_size)\n",
    "val_ds = shuffled_ds.skip(20000).take(5000).batch(batch_size)\n",
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "254/625 [===========>..................] - ETA: 1:28 - loss: 19280.0801 - accuracy: 0.0049"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model.fit(x=train_ds, batch_size=batch_size, epochs=80, callbacks=callbacks, validation_data=val_ds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "accf17c8cddd7598f858c901abd76bdd6a40d95d35cb16ec1025b995904db703"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
