{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv1D, LSTM, MaxPool2D, Flatten, InputLayer, Reshape, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = \"E:\\\\595DeepLearning\\\\TermProject\\\\data_road\\\\training\"\n",
    "training_data_path = \"E:\\\\595DeepLearning\\\\TermProject\\\\data_road\\\\training\\\\image_2\"\n",
    "label_data_path = \"E:\\\\595DeepLearning\\\\TermProject\\\\data_road\\\\training\\\\gt_image_2\"\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(600,160,6)),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        MaxPool2D(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        MaxPool2D(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        MaxPool2D(),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        TimeDistributed(LSTM(64, return_sequences=True)),\n",
    "        Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "        TimeDistributed(LSTM(64, return_sequences=True)),\n",
    "        Conv2D(64, (1,5), strides=(1,4), activation='relu'),\n",
    "        Conv2D(1, (1,4), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(600, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000000.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000001.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000002.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000003.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000004.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000005.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000006.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000007.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000008.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000009.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000010.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000011.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000012.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000013.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000014.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000015.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000016.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000017.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000018.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000019.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000020.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000021.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000022.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000023.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000024.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000025.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000026.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000027.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000028.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000029.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000030.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000031.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000032.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000033.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000034.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000035.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000036.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000037.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000038.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000039.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000040.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000041.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000042.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000043.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000044.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000045.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000046.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000047.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000048.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000049.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000050.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000051.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000052.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000053.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000054.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000055.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000056.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000057.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000058.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000059.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000060.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000061.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000062.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000063.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000064.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000065.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000066.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000067.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000068.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000069.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000070.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000071.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000072.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000073.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000074.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000075.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000076.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000077.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000078.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000079.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000080.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000081.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000082.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000083.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000084.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000085.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000086.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000087.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000088.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000089.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000090.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000091.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000092.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000093.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000094.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\umm_000095.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000000.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000001.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000002.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000003.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000004.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000005.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000006.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000007.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000008.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000009.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000010.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000011.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000012.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000013.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000014.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000015.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000016.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000017.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000018.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000019.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000020.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000021.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000022.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000023.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000024.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000025.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000026.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000027.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000028.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000029.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000030.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000031.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000032.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000033.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000034.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000035.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000036.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000037.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000038.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000039.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000040.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000041.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000042.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000043.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000044.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000045.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000046.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000047.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000048.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000049.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000050.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000051.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000052.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000053.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000054.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000055.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000056.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000057.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000058.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000059.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000060.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000061.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000062.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000063.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000064.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000065.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000066.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000067.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000068.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000069.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000070.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000071.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000072.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000073.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000074.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000075.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000076.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000077.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000078.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000079.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000080.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000081.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000082.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000083.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000084.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000085.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000086.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000087.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000088.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000089.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000090.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000091.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000092.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000093.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\um_000094.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000000.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000001.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000002.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000003.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000004.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000005.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000006.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000007.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000008.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000009.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000010.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000011.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000012.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000013.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000014.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000015.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000016.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000017.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000018.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000019.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000020.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000021.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000022.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000023.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000024.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000025.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000026.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000027.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000028.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000029.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000030.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000031.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000032.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000033.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000034.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000035.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000036.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000037.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000038.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000039.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000040.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000041.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000042.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000043.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000044.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000045.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000046.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000047.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000048.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000049.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000050.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000051.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000052.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000053.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000054.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000055.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000056.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000057.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000058.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000059.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000060.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000061.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000062.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000063.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000064.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000065.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000066.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000067.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000068.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000069.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000070.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000071.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000072.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000073.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000074.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000075.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000076.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000077.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000078.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000079.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000080.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000081.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000082.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000083.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000084.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000085.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000086.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000087.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000088.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000089.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000090.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000091.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000092.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000093.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000094.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000095.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000096.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n",
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\image_2\\uu_000097.png\n",
      "image_tensor_resized.shape (160, 600, 5)\n",
      "image_tensor_cropped.shape (160, 600, 5)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "\n",
    "plot_train_images = False\n",
    "resized_input_image_array = []\n",
    "cropped_input_image_array = []\n",
    "# print(os.listdir(data_path))\n",
    "image_paths = os.listdir(training_data_path)\n",
    "for image_filename in image_paths:\n",
    "    image_path = training_data_path + \"\\\\\" + image_filename\n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    resized = cv2.resize(image, dsize=(600, 160), interpolation=cv2.INTER_CUBIC)\n",
    "#     print(image.shape)\n",
    "    height, width, _ = image.shape\n",
    "    ymin = int(height/2-80)\n",
    "    ymax = int(height/2+80)\n",
    "    xmin = int(width/2-300)\n",
    "    xmax = int(width/2+300)\n",
    "#     print(ymin)\n",
    "#     print(ymax)\n",
    "#     print(xmin)\n",
    "#     print(xmax)\n",
    "    cropped = image[ymin:ymax, xmin:xmax]\n",
    "#     print(height, width)\n",
    "#     cv2.imshow(resized, )\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_axes([0,0,1,1])\n",
    "#     fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "#     ax1.imshow(resized)\n",
    "#     ax1.set_title(\"resized\")\n",
    "#     ax2.imshow(cropped)\n",
    "#     ax2.set_title(\"cropped\")\n",
    "#     print(resized.shape)\n",
    "#     print(cropped.shape)\n",
    "    rows = np.ndarray([160,600])\n",
    "    for i in range(160):\n",
    "#         print(i+1)\n",
    "        rows[i, :] = i+1  * np.ones([600])\n",
    "#     print(\"rows\", rows[:,0:5])\n",
    "#     print(\"rows.shape\", rows.shape)\n",
    "    columns = np.ndarray([160,600])\n",
    "#     print(\"columns.shape\", columns.shape)\n",
    "    for i in range(600):\n",
    "        columns[:, i] = i+1 * np.ones([160])\n",
    "#     print(\"columns\", columns[0:5,:])\n",
    "    rows = np.expand_dims(rows, 2)\n",
    "    columns = np.expand_dims(columns, 2)\n",
    "#     print(\"resized.shape\", resized.shape)\n",
    "#     print(\"rows.shape\", rows.shape)\n",
    "#     print(\"columns.shape\", columns.shape)\n",
    "    resized = resized.astype('float32')\n",
    "    resized /= 255.0\n",
    "    cropped = cropped.astype('float32')\n",
    "    cropped /= 255.0\n",
    "    image_tensor_resized = np.concatenate([resized, rows, columns], axis=2)\n",
    "    image_tensor_cropped = np.concatenate([cropped, rows, columns], axis=2)\n",
    "#     print(\"image_tensor_resized.shape\", image_tensor_resized.shape)\n",
    "#     print(\"image_tensor_cropped.shape\", image_tensor_cropped.shape)\n",
    "    if plot_train_images:\n",
    "        fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "        ax1.imshow(image_tensor_resized[:,:,0:3])\n",
    "        ax1.set_title(\"resized\")\n",
    "        ax2.imshow(image_tensor_cropped[:,:,0:3])\n",
    "        ax2.set_title(\"cropped\")\n",
    "    resized_input_image_array.append(image_tensor_resized)\n",
    "    cropped_input_image_array.append(image_tensor_cropped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\595DeepLearning\\TermProject\\data_road\\training\\gt_image_2\\um_lane_000000.png\n",
      "(375, 1242, 3)\n",
      "1242\n",
      "375\n",
      "<class 'numpy.ndarray'>\n",
      "[1. 0. 1.]\n",
      "[0. 0. 1.]\n",
      "column.size 1125\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAACUCAYAAACZbDLrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAATHklEQVR4nO3de7ScVX3G8e+TkxuQhAQDMSQBAkQwdFUuaQr1Rr2UiCxDtbShVaGgWKVdXqo1aFuqa7UF7aJK8RYBxYrELEShVBfG1Fa7RDBB0IQQCITLkUBA7ookgV//+O3pGcK5zcnMmZn3PJ+1zpqZPe+cs/e5PGfP3vvdryICMzOrnnHtroCZmbWGA97MrKIc8GZmFeWANzOrKAe8mVlFOeDNzCrKAW9jhqS7Jb1uGMeFpENH+DVG/FqzZnPAm5lVlAPezKyiHPA25khaLOl6SY9J2irpIkkTdznsREl3SXpY0icljat7/RmSNkp6VNJ1kg4c5SaYDYsD3saiZ4H3AzOB44DXAu/Z5Zg/BBYBRwNLgTMAJJ0MfAR4M7Av8EPgitGotFmjHPA25kTEuoj4cUTsjIi7gS8Ar97lsPMj4pGIuBf4FHBqKX8X8M8RsTEidgL/BBzpXrx1Ige8jTmSXiLpWkkPSHqCDOmZuxx2X939e4D9y/0DgU+X4Z3HgEcAAXNaXG2zhjngbSz6HHAbsCAippFDLtrlmHl19w8A7i/37wPeFRHT6z72iIgftbzWZg1ywNtYNBV4AnhK0uHAu/s55kOSZkiaB7wX+Hop/zxwjqQjACTtLemU0ai0WaMc8DYWfRD4U+BJ4Iv0hXe9q4F1wM3AfwKXAETEN4HzgZVleGc98IbWV9mscfIFP8zMqsk9eDOzimpZwEtaImmTpM2Slrfq65iZWf9aMkQjqQe4HXg90Av8BDg1Im5t+hczM7N+taoHvxjYHBF3RcR2YCV5NqCZmY2SVgX8HJ5/okgvPhHEzGxUjW/R5931pBGA540FSToLOCsf7XUMHN6iqpiZVdW6hyNi34GebVXA9/L8MwHn0ncmIAARsQJYASAtCljboqqYmVWV7hns2VYN0fwEWCBpftmGdRlwTYu+lpmZ9aMlPfiI2CnpL4HrgB7g0ojY0IqvZWZm/WvVEA0R8W3g2636/GZmNjifyWpmVlEOeDOzinLAm5lVlAPezKyiHPBmZhXlgDczqygHvJlZRTngzcwqygFvZlZRDngzs4pywJuZVZQD3sysohzwZmYV5YA3M6soB7yZWUU54M3MKsoBb2ZWUQ54M7OKGjLgJV0qaZuk9XVl+0haLemOcjuj7rlzJG2WtEnSCa2quJmZDW44PfgvA0t2KVsOrImIBcCa8hhJC4FlwBHlNZ+V1NO02pqZ2bANGfAR8QPgkV2KlwKXlfuXASfXla+MiGciYguwGVjcnKqamVkjRjoGPysitgKU2/1K+RzgvrrjekuZmZmNsmZPsqqfsuj3QOksSWslrYWHmlwNMzMbacA/KGk2QLndVsp7gXl1x80F7u/vE0TEiohYFBGLYN8RVsPMzAYy0oC/Bjit3D8NuLqufJmkSZLmAwuAG3evimZmNhLjhzpA0hXA8cBMSb3AucB5wCpJZwL3AqcARMQGSauAW4GdwNkR8WyL6m5mZoNQRL9D5KNbCS0KWNvuapiZdRmty2Hu/vlMVjOzinLAm5lVlAPezKyiHPBmZhXlgDczqygHvJlZRTngzcwqygFvZlZRDngzs4pywJuZVZQD3sysohzwZmYV5YA3M6soB7yZWUU54M3MKsoBb2ZWUQ54M7OKcsCbmVXUkAEvaZ6k70vaKGmDpPeW8n0krZZ0R7mdUfeacyRtlrRJ0gmtbIC10nPAsw1+tPYSkO6RmA3fkBfdJi+e/dcRcZOkqcA6SauB04E1EXGepOXAcuDDkhYCy4AjgP2B70l6iS++PVpqAfub8tELPAjcAGxv8HPdBdw9yPN7AROBg4GpwLHAq8r95hgHzABeCrwCeCVwE/BF8mrvZjawIQM+IrYCW8v9JyVtBOYAS4Hjy2GXAf8NfLiUr4yIZ4AtkjYDi4Hrm11520GGdi/wK2Ad8BjwY+A+4H7gceDXZG+8UePLx37ANGAuMB84HJgHLCDjdx8y6McBGmljXmAC8GngJODFpSYC3kD2Li4FLgZ+wchaZ1Z1w+nB/z9JBwFHkd3BWSX8iYitkvYrh80hE6amt5TZiNSGSR4CngZ+DtwD3Fpu7yG/xTuAZ0bw+XvIKJ0JTAdeQgb5QuBA4ABgX7JXXjt2dOwEppTa1P/bUCn7O+CdwHeAC8nvjIPerM+wA17SFOAbwPsi4glpwJ5af0+8YGBW0lnAWfnogOFWo6KifDxJhvTtZHBvAu4EtgCbySGXpxjZOPcUspd9CBnWv0sG+uLy+GAyvPcqxzevJz5SAfwQeOsAzwuYDfw58Gbyl/NCYD0OejMYZsBLmkD+/VweEVeV4gclzS6999nAtlLeS75/r5lLjhU8T0SsAFbk51/U2pm5jhH0hfRW8tuyGbiDDPINZC/9lzQ+YTmB/HG+mAzs3wb2Jnvic8ie+d7Ai8pxzR1OaZVN5CDUpEGOEfmv6gzgLcAa8hfrfxjZexqzqhgy4JVd9UuAjRFxQd1T1wCnAeeV26vryr8m6QJyknUBcGMzK918zzGyPl8ADzP45OUD5ETljcCj5BThI+T/w2fJgYjh6iF74TPJce8F5DDKYeTY+BxyvLw2+dn9a07uJN/XDBbwNbWgfwvwRuD7wAXkuwAHvY1Fw+nBvxx4G/BzSTeXso+Qwb5K0pnkgoZTACJig6RV5CDxTuDs9q+g2Ql8iYFXhDxAVrdRUT7n04Mcs53stTdiGhnQC+hbnTId+B1yqGU+2WPfoxzf+T3xkdoG3EauoGnEZGAJ8Pvk1PPFwFXAE02tnVlnU0T7R0dyiGZtC79CAJcDZ9L4UsFWmFA+ZpMBfiQZ4McBe5LDKVPJ4ZQeumU4pVU+CXxwNz/Hs8At5Kqcb+Ggt6rQuohYNNCzDa2i6V4C/gj4NnDFKH3NHrIfObN8HEL2vBeU+y8GZpGBPoEqDKe0yi3kANrufId6gKPJsca/IoP+anL4x6yqKhrw9e9KdpD9tQBOJPtvgw2pNKKHnLjsIcfB64dTFpXHB5IBPrm8Zuz2xEfqdvJ91+ShDhyG8eRP5kvk0M8V5f7WJnxus07TxUM0QQZ1kGvEHyVP6FlH9vduLuVPkCtVgpzc3NHg15lIxsJccvz7KPLknmPJsfKF5fl9yKAXDvHmmk7+VA9uweeuzaKsAL5MzsaYdY+uG6IJ+laWPE6+if4N8DMyuG8hT73fCfyU7Ns9Sl8vvdEAh/w21IZTZpFDKYeSkbKAXJkyqxzj4ZTR9jiwkdYEvMif9j8C7wC+AHydXOvrtfTW7Tok4H9N7nZQW3hzI7mwbRu5Jvy5cszu6CH7glPI8N6D7IXPIEdnp5HL9yfQtyjPPfFOEORvxIm07icyjpwZOQ/4ELAKuIhch9/+97hmI9MhQzRTIgN8d+syifyfNY8M8mPoW50yldyyalIpAw+ndI/XkVPko7VRQpBdiyuAz5DzAO3/SzHb1eBDNB0S8BpmJUT2xPcklxDOBg4ilxXWbmvDLLXhFAd4FRxK9uJnDHVgk9VOZfsaGfS12RyzztB1AV8L8enksMkh5AmxR5ArVo4st/uTE6AT615nVbUnOQ3/0jZ9/VrQXwZ8gpy+N2u/rphk3ZPcMmpv+oZTDiOHU/bGQylWWx/VroAXuafmB8jti/+BXEff6DnKZqOpQ3rwx5Rlkg5xG9hZwOfpjN+S7cB1wLnkgtz2/xXZ2DR4D75D1vu5h25D20hnbDQBOTB4Erlz5bnkQlqzTtMhAW82tLvprK0FRE76/j3Zm/8TRvNyKGZDc8Bb13iAXJfeaURO/X+ZPElqIX4/ap3BAW9dYwet3XN0d00GTiYvTvwRcg2YWTs54K2rdPr2AbXVNh8HrgVeTy76NWsHB7xZC4wDXkle5/KL5J6iZqPNAW/WQlOB04H/Bf4CD9vY6HLAm7WYyM2mLyJPjjoe/+HZ6Bjy90zSZEk3SrpF0gZJHyvl+0haLemOcjuj7jXnSNosaZOkE1rZALNu0QO8GvgP4EI8bGOtN5yOxDPAayLiZeRqsCWSjgWWA2siYgF5vsdyAEkLgWXk5jFLgM9K8jyTGdmbnwK8B/ge8C76Lp1u1mxDBnykp8rD2tWiA1hK7r1EuT253F8KrIyIZyJiC7kB3+JmVtqs24ncIfPfyMvBH9be6lhFDWsoUFKPpJvJK3CsjogbgFkRsRWg3NbO1p4D3Ff38t5SZrbb9mx3BZpsAtkz+h55RalJgx5t1phhBXxEPBsRR5JzRYsl/dYgh/d3Et8L9mKSdJaktZLWevNVG44J5LW3qqY2CfsZ4KvkRSLNmqGhyfyIeIw8UW8J8KCk2QDldls5rJe8pFLNXOD+fj7XiohYlDuh7dt4zW3MmQzs1e5KtNBE4C1kb/503Ju33TecVTT7Sppe7u9BXj3tNuAa4LRy2GnkCjBK+TJJkyTNJzskNza53jYG7cfzew5VJOAAYAU5sXVIe6tjXW44F/yYDVxWVsKMA1ZFxLWSrgdWSToTuBc4BSAiNkhaRd8VtM+OiGdbU30bSw4me/FjwQTgj8nVCeeSFwF/pq01sm7UIRf8WBSdvY2UdYK3kb3asbZT43bgSuBvgS1trot1mq644IfZ0F7W7gq0yUTgVHJs/lS857wNnwPeusZ+jL3ee43IIapL8eZlNnwOeOsKk8lTo8e6ycDbyd78KQxvEs3GLge8dYX9gP3bXYkOIXJ1zVfI1TZz21sd62AOeOsKpwGz2l2JDiKyN3862Zt/Mx6btxdywFvHm0aeADRWx98HI3Ifm8vJM2H9LsfqOeCt470Jj78PZTK5l80acrc/j80bOOCtw00E3okDazgEHA58Dfg0eYaijW0OeOtoxwEDnsVh/doTeDewGngjvuj3WOaAt44lcnLVF8RonICF5BYH/4onqMcqB7x1rEPJHqgnV0dGZG/+bOA6cgtY9+bHFge8dax34I2km2Ecuc3DlcC/4O/pWOK5K+tIM8nVM+69D+w54Gn6uZrOIM4k5zQ+DPyoFZWyjuKAt470avKX864RvPZ24JfNrc6QfgncRGNhu7ueBm4hg75RTw19iFWAA9460jXkuPFI/Ia8EIHZWNch+8HrSWBTu+vRAjOBh9tdiRZwu7qL29VdGmnXgREx4LRKp/TgNw22aX23krTW7eoebld3cbuG5lU0ZmYV5YA3M6uoTgn4Fe2uQIu4Xd3F7eoubtcQOmKS1czMmq9TevBmZtZkbQ94SUskbZK0WdLydtenEZLmSfq+pI2SNkh6bynfR9JqSXeU2xl1rzmntHWTpBPaV/vBSeqR9FNJ15bHVWjTdElXSrqt/MyOq0i73l9+/9ZLukLS5G5sl6RLJW2TtL6urOF2SDpG0s/LcxdKausJ0QO065Pl9/Bnkr4paXrdc81rV0S07YPc++hO8oLxE8kT8xa2s04N1n82cHS5P5U8iXIh8AlgeSlfDpxf7i8sbZwEzC9t72l3OwZo2wfIrcWvLY+r0KbLgHeU+xOB6d3eLmAOsAXYozxeRV7Jr+vaBbwKOBpYX1fWcDuAG8mdpgV8B3hDB7brD4Dx5f75rWpXu3vwi4HNEXFXRGwHVpIXpOkKEbE1Im4q958ENpJ/cEvJMKHcnlzuLwVWRsQzEbEF2Ex+DzqKpLnkRo4X1xV3e5umkX9olwBExPaIeIwub1cxHthD0nhyA8n76cJ2RcQPgEd2KW6oHZJmA9Mi4vrIVPxK3Wvaor92RcR3I6J2wvWP6bt2elPb1e6AnwPcV/e4t5R1HUkHAUcBNwCzImIr5D8BYL9yWLe091PA3/D8bU66vU0HAw8BXypDTxdL2osub1dE/ILcJPJeYCvweER8ly5vV51G2zGn3N+1vJOdQfbIocntanfA9zeG1HXLeiRNAb4BvC8inhjs0H7KOqq9kk4CtkXEuuG+pJ+yjmpTMZ58m/y5iDgK+BX5ln8gXdGuMia9lHw7vz+wl6S3DvaSfso6rl3DMFA7uqp9kj5Kbp10ea2on8NG3K52B3wvMK/u8Vzy7WXXkDSBDPfLI+KqUvxgeUtFud1WyruhvS8H3iTpbnLI7DWSvkp3twmynr0RcUN5fCUZ+N3ertcBWyLioYjYAVwF/B7d366aRtvRS99wR315x5F0GnAS8Gdl2AWa3K52B/xPgAWS5kuaCCwjNxLsCmUW+xJgY0RcUPfUNeTV5ii3V9eVL5M0SdJ8YAE5cdIxIuKciJgbEQeRP4//ioi30sVtAoiIB4D7JB1Wil4L3EqXt4scmjlW0p7l9/G15FxQt7erpqF2lGGcJyUdW74fb697TceQtITclv9NEfHruqea2652zi6Xf1onkqtP7gQ+2u76NFj3V5Bvk34G3Fw+TgReBKwB7ii3+9S95qOlrZto8+z+MNp3PH2raLq+TcCRwNry8/oWMKMi7foYcBuwHvh3cgVG17ULuIKcR9hB9ljPHEk7yGuarC/PXUQ5obPD2rWZHGuv5cbnW9Eun8lqZlZR7R6iMTOzFnHAm5lVlAPezKyiHPBmZhXlgDczqygHvJlZRTngzcwqygFvZlZR/weNTCP1mNOgTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare training labels\n",
    "label_paths = os.listdir(label_data_path)\n",
    "\n",
    "plot_label_images = True\n",
    "for label_image in label_paths:\n",
    "    label_image = \"um_lane_000000.png\"\n",
    "    image_path = label_data_path + \"\\\\\" + label_image\n",
    "    print(image_path)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    print(image.shape)\n",
    "    print(image.shape[1])\n",
    "    print(image.shape[0])\n",
    "    print(type(image))\n",
    "    \n",
    "    column = image[:,i]\n",
    "    print(\"column.size\", column.size)\n",
    "\n",
    "    for i in range(image.shape[1]):\n",
    "        #find max of purple here\n",
    "        print(image[300,600])\n",
    "        print(image[300,1200])\n",
    "#         for j in range(image.shape[0]):\n",
    "        column = image[:,i]\n",
    "        print(\"column.size\", column.size)\n",
    "\n",
    "#             print(j)\n",
    "#             break\n",
    "        print(i)\n",
    "        break\n",
    "    \n",
    "    if plot_label_images:\n",
    "        fig, (ax1) = plt.subplots(1,1)\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title(\"label\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a132e1c5f1b31d5e927d688f965514e030dfbafb3124753db69ec43e5ee86536"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
